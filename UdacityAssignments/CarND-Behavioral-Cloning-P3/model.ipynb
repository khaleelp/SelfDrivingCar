{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix error with TF and Keras\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, ELU\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module imported\n"
     ]
    }
   ],
   "source": [
    "print(\"module imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ch, row, col = 3, 160, 320\n",
    "channels, rows, columns = 3, 66, 200  # camera format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "6615\n",
      "735\n"
     ]
    }
   ],
   "source": [
    "#Fetch data from pickle file\n",
    "with open('data/driving_data.p', mode='rb') as f:\n",
    "    driving_data = pickle.load(f)\n",
    "\n",
    "center_images = driving_data['center_images']\n",
    "left_images = driving_data['left_images']\n",
    "right_images = driving_data['right_images']\n",
    "labels = driving_data['labels']\n",
    "\n",
    "#shuffle a dataset\n",
    "#images, labels = shuffle(center_images, labels)\n",
    "\n",
    "# split train & valid data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(center_images, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train[0].shape)\n",
    "print(len(X_train))\n",
    "print(len(X_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_grayscale(image_data):\n",
    "    a = -0.5\n",
    "    b = 0.5\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (image_data - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "#center_images = normalize_grayscale(center_images)\n",
    "#left_images = normalize_grayscale(left_images)\n",
    "#right_images = normalize_grayscale(right_images)\n",
    "\n",
    "#center_images = (center_images - 127)/128 \n",
    "#left_images = (left_images - 127)/128\n",
    "#right_images = (right_images - 127)/128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJsAAACTCAYAAACZMmvhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni6gaorBFVA3/D2Y1ZRff4Ok4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1271c5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of labels count\n",
    "\n",
    "plt.hist(labels, bins=70)\n",
    "plt.title('angle histogram')\n",
    "plt.xlabel('steering angle')\n",
    "plt.ylabel('counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data can not convert to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-305bc91997ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3027\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3030\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1818\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   4920\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   4921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4922\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4923\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    447\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    448\u001b[0m                 not np.can_cast(self._A.dtype, np.float)):\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data can not convert to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         if (self._A.ndim not in (2, 3) or\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data can not convert to float"
     ]
    }
   ],
   "source": [
    "#Randomly print few images\n",
    "plt.figure(figsize=(16,6))\n",
    "for i in range(36):\n",
    "    random_index = np.random.randint(0,len(X_train))\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.imshow(X_train[random_index].squeeze(), cmap=\"gray\");\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def commaai_model(time_len=1):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(ch, row, col),\n",
    "            output_shape=(ch, row, col)))\n",
    "    model.add(Convolution2D(16, 8, 8, input_shape=(3,160,320), subsample=(4, 4), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def nvidia_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    INIT='glorot_uniform' # 'he_normal', glorot_uniform\n",
    "    keep_prob = 0.2\n",
    "    reg_val = 0.01\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(row, col, ch),\n",
    "            output_shape=(row, col, ch)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT))\n",
    "    # W_regularizer=l2(reg_val)\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=INIT))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(keep_prob))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\") # , metrics=['accuracy']\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#custom rows and columns to fit Nvidia model\n",
    "custom_rows, custom_cols = 66, 200\n",
    "\n",
    "def get_image(center_images, left_images, right_images, labels, index, image_offset=0.25):\n",
    "    \n",
    "    camera = np.random.choice(['center', 'left', 'right'])\n",
    "\n",
    "    if camera == 'center':\n",
    "        image, steering = plt.imread(\"data/\"+center_images[index]), float(labels[index])\n",
    "    elif camera == 'left':\n",
    "        image, steering = plt.imread(\"data/\"+left_images[index]), float(labels[index])+image_offset\n",
    "    elif camera == 'right':\n",
    "        image, steering = plt.imread(\"data/\"+right_images[index]), float(labels[index])-image_offset\n",
    "\n",
    "    #Augment image \n",
    "    image, angle = augment_image(image, steering)\n",
    "    \n",
    "    image = cv2.resize(image, (custom_cols, custom_rows))\n",
    "    image = np.reshape(image, (1, custom_rows, custom_cols, channels))\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "def flip_image(image, angle):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(image, 1), -angle\n",
    "    else:\n",
    "        return image, angle\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    rows,cols,channel = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), random.uniform(-5, 5), 1)\n",
    "    return cv2.warpAffine(image,M,(cols,rows)), angle\n",
    "\n",
    "def augment_image(image, angle):\n",
    "    \n",
    "    #Crop image\n",
    "    #Flip image\n",
    "    image, angle = flip_image(np.copy(image),angle)\n",
    "    #Rotate image\n",
    "    image, angle = rotate_image(image,angle)\n",
    "    #Brightness\n",
    "    \n",
    "    return image, angle\n",
    "\n",
    "#Generator, and training\n",
    "def my_generator(center_images, left_images, right_images, labels, batch_size):\n",
    "    batch_train = np.zeros((batch_size, rows, columns, 3))\n",
    "    batch_angle = np.zeros(batch_size)\n",
    "    while True:\n",
    "        for index in range(batch_size):\n",
    "            image, angle = get_image(center_images, left_images, right_images, labels, index)\n",
    "            batch_train[i], batch_angle[i] = image, angle\n",
    "        yield batch_train, batch_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1917: UserWarning: Expected no kwargs, you passed 2\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6400/6400 [==============================] - 47s - loss: 0.3093 - acc: 0.7430    \n",
      "Epoch 2/2\n",
      "6400/6400 [==============================] - 52s - loss: 0.0548 - acc: 0.9642    \n",
      "model training complete\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "EPOCHS = 2\n",
    "\n",
    "model = nvidia_model()\n",
    "\n",
    "#print model summary\n",
    "#model.summary()\n",
    "\n",
    "# Compile model using Adam optimizer\n",
    "# and loss computed by mean squared error\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'], \n",
    "              validation_data=(X_validation, y_validation), \n",
    "              verbose=1)\n",
    "\n",
    "my_generator = my_generator(center_images, left_images, right_images, labels, batch_size)\n",
    "\n",
    "# Model training\n",
    "# TODO: Add validation data\n",
    "history = model.fit_generator(\n",
    "    my_generator,\n",
    "    samples_per_epoch=256*25, # of training samples\n",
    "    nb_epoch=EPOCHS,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "model_json = 'model.json'\n",
    "model_weights = 'model.h5'\n",
    "\n",
    "json_string = model.to_json()\n",
    "try:\n",
    "    os.remove(model_json)\n",
    "    os.remove(model_weights)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with open(model_json, 'w') as jfile:\n",
    "    json.dump(json_string, jfile)\n",
    "model.save(model_weights)\n",
    "\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
