{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from pandas.io.parsers import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create new data by duplicating existing images by perturbing the angles a bit.\n",
    "\"\"\"\n",
    "#Credit\n",
    "#https://medium.com/@acflippo/cloning-driving-behavior-by-augmenting-steering-angles-5faf7ea8a125#.41vw9spjy\n",
    "def perturb_angle(angle):\n",
    "    new_angle = angle* (1 + np.random.uniform(-1, 1)/30.0)\n",
    "    return min(1, new_angle) if new_angle > 0 else max(-1, new_angle)\n",
    "\n",
    "def draw_data_hist(data, header):\n",
    "    plt.figure()\n",
    "    print(header,\"max value is\", max(data))\n",
    "    print(header,\"min value is\", min(data))\n",
    "    unique_values, counts = np.unique(data, return_counts=True)\n",
    "    plt.hist(data, bins=min(len(counts), 100))\n",
    "    plt.title(header)\n",
    "    plt.axis([min(data), max(data), 0, max(counts)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified data 25956\n"
     ]
    }
   ],
   "source": [
    "#LOAD and MODIFY data\n",
    "drive_info = read_csv(\"data/driving_log.csv\", header=0, usecols=[0,1,2,3]).as_matrix();\n",
    "\n",
    "modified_data = []\n",
    "for row in drive_info:\n",
    "    center = copy.deepcopy(row)\n",
    "    center[1] = row[3] #original_angle\n",
    "    modified_data.append(center)\n",
    "\n",
    "    left = copy.deepcopy(row)\n",
    "    left[0] = left[1] #left_image\n",
    "    left[1] = left[3]+0.25\n",
    "    modified_data.append(left)\n",
    "    \n",
    "    right = copy.deepcopy(row)\n",
    "    right[0] = right[2] #right image\n",
    "    right[1] = right[3]-0.25\n",
    "    modified_data.append(right)\n",
    "\n",
    "# add more samples for steering angle more than 0.5 or less then -0.5\n",
    "\n",
    "insufficient_data = [data for data in modified_data if abs(float(data[3])) > 0.5]\n",
    "for line in insufficient_data:\n",
    "    for i in range(0, 14):\n",
    "        new_line = copy.deepcopy(line)\n",
    "        new_line[1] = perturb_angle(line[3])\n",
    "        modified_data.append(new_line)\n",
    "\n",
    "\n",
    "driving_data = np.array(modified_data)    \n",
    "print('modified data', len(modified_data))\n",
    "#draw_data_hist(modified_data[:, 1], 'modified train angles');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "validation_data=[]\n",
    "\n",
    "step = 0.01\n",
    "per_step = 14\n",
    "curent_start = 0.0\n",
    "\n",
    "\"\"\"\n",
    "Utility method to extract data from bin\n",
    "\"\"\"\n",
    "def extract_data_from_bin(current_bin):\n",
    "    validation_bin = []\n",
    "    \n",
    "    if len(current_bin) > per_step:\n",
    "        current_bin = shuffle(current_bin)\n",
    "        validation_bin = current_bin[per_step:2*per_step]\n",
    "        for line in validation_bin:\n",
    "            validation_data.append(line)\n",
    "        current_bin = current_bin[0:per_step]\n",
    "    for line in current_bin:\n",
    "        training_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained data 1307\n",
      "validation data 1141\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "sample_bin_start = 0.0\n",
    "sample_bin_end = 1.0\n",
    "sample_bin_step = 0.01\n",
    "current_bin = sample_bin_start\n",
    "    \n",
    "while curent_start<sample_bin_end:\n",
    "    current_bin = [data for data in modified_data if (curent_start < abs(data[1])) and (abs(data[1])<=curent_start+step)]\n",
    "    extract_data_from_bin(current_bin)\n",
    "    curent_start = curent_start+step\n",
    "        \n",
    "zero_bin = [data for data in modified_data if (data[1]==0.0)]\n",
    "extract_data_from_bin(zero_bin)\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "validation_data = np.array(validation_data)\n",
    "        \n",
    "#draw_data_hist(abs(training_data[:,1]), 'train angles');\n",
    "#draw_data_hist(abs(validation_data[:,1]), 'validation angles');\n",
    "\n",
    "print(\"trained data\", len(training_data))\n",
    "print(\"validation data\", len(validation_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation angles saved to pickle file\n"
     ]
    }
   ],
   "source": [
    "# prepare data to save\n",
    "\n",
    "pickle_data = []\n",
    "validation_pickle = []\n",
    "\n",
    "for row in training_data:  \n",
    "    pickle_data.append({ 'center': row[0], 'angle': row[1] })\n",
    "    \n",
    "for row in validation_data:  \n",
    "    validation_pickle.append({ 'center': row[0], 'angle': row[1] })\n",
    "    \n",
    "training_file = 'train.p'\n",
    "with open(\"data/\"+training_file, 'wb') as handle:\n",
    "    pickle.dump(np.array(pickle_data), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "validation_file = 'validation.p'\n",
    "with open(\"data/\"+validation_file, 'wb') as handle:\n",
    "    pickle.dump(np.array(validation_pickle), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Training and validation angles saved to pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMAGE PRE-PROCESSING TECHNIQUES\n",
    "\"\"\"\n",
    "def img_pre_process(image):\n",
    "    roi = image[60:140, :, :] #Cut top and bottom of image\n",
    "    image = cv2.resize(roi, (64,64), interpolation=cv2.INTER_AREA) #reducing image size so that model runs faster\n",
    "    return image\n",
    "\n",
    "#Image brigtness method\n",
    "#Credit: https://github.com/mohankarthik/CarND-BehavioralCloning-P3/blob/master/model.py\n",
    "def img_change_brightness(img):\n",
    "    # Convert the image to HSV\n",
    "    temp = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute a random brightness value and apply to the image\n",
    "    brightness = 0.25 + np.random.uniform()\n",
    "    temp[:, :, 2] = temp[:, :, 2] * brightness\n",
    "\n",
    "    # Convert back to RGB and return\n",
    "    return cv2.cvtColor(temp, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "#translate image and compensate for the translation on the steering angle\n",
    "def translate_image(image, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = image.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * 0.004 # multiply by steering angle units per pixel\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    image = cv2.warpAffine(image, tr_M, (cols,rows), borderMode=1)\n",
    "    return image, steering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER_PATH = 'data'\n",
    "\n",
    "def read_image(image_path):\n",
    "    full_image_path = os.path.join(FOLDER_PATH, image_path.strip())\n",
    "    image = mpimg.imread(full_image_path)\n",
    "    return img_pre_process(image)\n",
    "\n",
    "# use flipping to avoid bias to left\\right turns\n",
    "# use brightness augmentaion to generalize to t2\n",
    "def generate_steering_angle(data, batch_size=128):\n",
    "    X = []\n",
    "    Y = []\n",
    "    while True:\n",
    "        data = shuffle(data)    \n",
    "        for line in data:\n",
    "            image = read_image(line['center'])\n",
    "            angle = line['angle']\n",
    "            image_brightened = img_change_brightness(image)\n",
    "            X.append(image_brightened)\n",
    "            Y.append(angle)\n",
    "            \n",
    "            flipped_image = cv2.flip(image, 1)\n",
    "            flipped_image_brightened = img_change_brightness(flipped_image)\n",
    "            X.append(flipped_image_brightened)\n",
    "            Y.append(-angle)\n",
    "            \n",
    "            translated_image, translated_angle = translate_image(image_brightened, angle)\n",
    "            X.append(translated_image)\n",
    "            Y.append(translated_angle)\n",
    "\n",
    "            translated_flipped_image, translated_flipped_angle = translate_image(flipped_image_brightened, angle)\n",
    "            X.append(translated_flipped_image)\n",
    "            Y.append(translated_flipped_angle)\n",
    "\n",
    "            if len(X)>=batch_size:\n",
    "                X, Y = shuffle(X, Y)\n",
    "                yield np.array(X), np.array(Y) # (image, steering angle)\n",
    "                X=[]\n",
    "                Y=[]\n",
    "            \n",
    "\n",
    "def generate_validation(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    while True:\n",
    "        data = shuffle(data)\n",
    "        for line in data:\n",
    "            angle = line['angle']\n",
    "            image = read_image(line['center'])\n",
    "\n",
    "            X.append(image)\n",
    "            Y.append(angle)\n",
    "            yield np.array(X), np.array(Y) # (image, steering angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=[64, 64, 3])\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # and a regression layer to predict steering angle\n",
    "    x = Dense(1000, activation='relu', name='fc1', W_regularizer=l2(0.0001))(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(250, activation='relu', name='fc2', W_regularizer=l2(0.0001))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1)(x)\n",
    "\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    # train only the top layers (which were randomly initialized)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #model = load_model(\"model.h5\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 1307\n",
      "validation size 1141\n",
      "Epoch 1/12\n",
      "  64/5228 [..............................] - ETA: 235s - loss: 1799.6263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-93bf2e4f5965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     nb_val_samples=len(validation_info)/7)\n\u001b[0m",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1900\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "training_pickle = 'data/train.p'\n",
    "with open(training_pickle, 'rb') as handle:\n",
    "    driving_info = pickle.load(handle)\n",
    "\n",
    "validation_pickle = 'data/validation.p'\n",
    "with open(validation_pickle, 'rb') as handle:\n",
    "    validation_info = pickle.load(handle)\n",
    "    \n",
    "print(\"train size\", len(driving_info))\n",
    "print(\"validation size\", len(validation_info))\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(\n",
    "    generate_steering_angle(driving_info, batch_size=32),\n",
    "    samples_per_epoch=len(driving_info)*4, \n",
    "    nb_epoch=12,\n",
    "    validation_data=generate_validation(validation_info),\n",
    "    nb_val_samples=len(validation_info)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "    \n",
    "print(\"model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
