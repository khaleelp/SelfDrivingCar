{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from pandas.io.parsers import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create new data by duplicating existing images by perturbing the angles a bit.\n",
    "\"\"\"\n",
    "#Credit\n",
    "#https://medium.com/@acflippo/cloning-driving-behavior-by-augmenting-steering-angles-5faf7ea8a125#.41vw9spjy\n",
    "def perturb_angle(angle):\n",
    "    new_angle = angle* (1 + np.random.uniform(-1, 1)/30.0)\n",
    "    return min(1, new_angle) if new_angle > 0 else max(-1, new_angle)\n",
    "\n",
    "def draw_data_hist(data, header):\n",
    "    plt.figure()\n",
    "    print(header,\"max value is\", max(data))\n",
    "    print(header,\"min value is\", min(data))\n",
    "    unique_values, counts = np.unique(data, return_counts=True)\n",
    "    plt.hist(data, bins=min(len(counts), 100))\n",
    "    plt.title(header)\n",
    "    plt.axis([min(data), max(data), 0, max(counts)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified data 25956\n"
     ]
    }
   ],
   "source": [
    "#LOAD and MODIFY data\n",
    "drive_info = read_csv(\"data/driving_log.csv\", header=0, usecols=[0,1,2,3]).as_matrix();\n",
    "\n",
    "modified_data = []\n",
    "for row in drive_info:\n",
    "    center = copy.deepcopy(row)\n",
    "    center[1] = row[3] #original_angle\n",
    "    modified_data.append(center)\n",
    "\n",
    "    left = copy.deepcopy(row)\n",
    "    left[0] = left[1] #left_image\n",
    "    left[1] = left[3]+0.25\n",
    "    modified_data.append(left)\n",
    "    \n",
    "    right = copy.deepcopy(row)\n",
    "    right[0] = right[2] #right image\n",
    "    right[1] = right[3]-0.25\n",
    "    modified_data.append(right)\n",
    "\n",
    "# add more samples for steering angle more than 0.5 or less then -0.5\n",
    "\n",
    "insufficient_data = [data for data in modified_data if abs(float(data[3])) > 0.5]\n",
    "for line in insufficient_data:\n",
    "    for i in range(0, 14):\n",
    "        new_line = copy.deepcopy(line)\n",
    "        new_line[1] = perturb_angle(line[3])\n",
    "        modified_data.append(new_line)\n",
    "\n",
    "driving_data = np.array(modified_data)    \n",
    "print('modified data', len(modified_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "validation_data=[]\n",
    "\n",
    "step = 0.01\n",
    "per_step = 19\n",
    "current_bin = 0.0\n",
    "\n",
    "\"\"\"\n",
    "Utility method to extract data from bin\n",
    "\"\"\"\n",
    "def extract_data_from_bin(current_bin_data):\n",
    "    validation_bin = []\n",
    "    \n",
    "    if len(current_bin_data) > per_step:\n",
    "        current_bin_data = shuffle(current_bin_data)\n",
    "        validation_bin = current_bin_data[per_step:2*per_step]\n",
    "        for line in validation_bin:\n",
    "            validation_data.append(line)\n",
    "        current_bin_data = current_bin_data[0:per_step]\n",
    "    for line in current_bin_data:\n",
    "        training_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin:len 0.0  :  143\n",
      "bin:len 0.01  :  196\n",
      "bin:len 0.02  :  215\n",
      "bin:len 0.03  :  201\n",
      "bin:len 0.04  :  226\n",
      "bin:len 0.05  :  387\n",
      "bin:len 0.060000000000000005  :  284\n",
      "bin:len 0.07  :  525\n",
      "bin:len 0.08  :  286\n",
      "bin:len 0.09  :  338\n",
      "bin:len 0.09999999999999999  :  373\n",
      "bin:len 0.10999999999999999  :  186\n",
      "bin:len 0.11999999999999998  :  270\n",
      "bin:len 0.12999999999999998  :  177\n",
      "bin:len 0.13999999999999999  :  338\n",
      "bin:len 0.15  :  317\n",
      "bin:len 0.16  :  296\n",
      "bin:len 0.17  :  504\n",
      "bin:len 0.18000000000000002  :  269\n",
      "bin:len 0.19000000000000003  :  359\n",
      "bin:len 0.20000000000000004  :  182\n",
      "bin:len 0.21000000000000005  :  161\n",
      "bin:len 0.22000000000000006  :  153\n",
      "bin:len 0.23000000000000007  :  155\n",
      "bin:len 0.24000000000000007  :  8851\n",
      "bin:len 0.25000000000000006  :  123\n",
      "bin:len 0.26000000000000006  :  155\n",
      "bin:len 0.2700000000000001  :  171\n",
      "bin:len 0.2800000000000001  :  121\n",
      "bin:len 0.2900000000000001  :  205\n",
      "bin:len 0.3000000000000001  :  351\n",
      "bin:len 0.3100000000000001  :  231\n",
      "bin:len 0.3200000000000001  :  271\n",
      "bin:len 0.3300000000000001  :  117\n",
      "bin:len 0.34000000000000014  :  220\n",
      "bin:len 0.35000000000000014  :  165\n",
      "bin:len 0.36000000000000015  :  98\n",
      "bin:len 0.37000000000000016  :  149\n",
      "bin:len 0.38000000000000017  :  100\n",
      "bin:len 0.3900000000000002  :  222\n",
      "bin:len 0.4000000000000002  :  130\n",
      "bin:len 0.4100000000000002  :  189\n",
      "bin:len 0.4200000000000002  :  262\n",
      "bin:len 0.4300000000000002  :  71\n",
      "bin:len 0.4400000000000002  :  54\n",
      "bin:len 0.45000000000000023  :  30\n",
      "bin:len 0.46000000000000024  :  91\n",
      "bin:len 0.47000000000000025  :  52\n",
      "bin:len 0.48000000000000026  :  59\n",
      "bin:len 0.49000000000000027  :  192\n",
      "bin:len 0.5000000000000002  :  205\n",
      "bin:len 0.5100000000000002  :  228\n",
      "bin:len 0.5200000000000002  :  214\n",
      "bin:len 0.5300000000000002  :  88\n",
      "bin:len 0.5400000000000003  :  70\n",
      "bin:len 0.5500000000000003  :  50\n",
      "bin:len 0.5600000000000003  :  67\n",
      "bin:len 0.5700000000000003  :  87\n",
      "bin:len 0.5800000000000003  :  101\n",
      "bin:len 0.5900000000000003  :  127\n",
      "bin:len 0.6000000000000003  :  93\n",
      "bin:len 0.6100000000000003  :  76\n",
      "bin:len 0.6200000000000003  :  72\n",
      "bin:len 0.6300000000000003  :  74\n",
      "bin:len 0.6400000000000003  :  78\n",
      "bin:len 0.6500000000000004  :  57\n",
      "bin:len 0.6600000000000004  :  56\n",
      "bin:len 0.6700000000000004  :  32\n",
      "bin:len 0.6800000000000004  :  30\n",
      "bin:len 0.6900000000000004  :  35\n",
      "bin:len 0.7000000000000004  :  37\n",
      "bin:len 0.7100000000000004  :  35\n",
      "bin:len 0.7200000000000004  :  16\n",
      "bin:len 0.7300000000000004  :  16\n",
      "bin:len 0.7400000000000004  :  35\n",
      "bin:len 0.7500000000000004  :  24\n",
      "bin:len 0.7600000000000005  :  14\n",
      "bin:len 0.7700000000000005  :  14\n",
      "bin:len 0.7800000000000005  :  12\n",
      "bin:len 0.7900000000000005  :  18\n",
      "bin:len 0.8000000000000005  :  10\n",
      "bin:len 0.8100000000000005  :  11\n",
      "bin:len 0.8200000000000005  :  8\n",
      "bin:len 0.8300000000000005  :  5\n",
      "bin:len 0.8400000000000005  :  0\n",
      "bin:len 0.8500000000000005  :  2\n",
      "bin:len 0.8600000000000005  :  0\n",
      "bin:len 0.8700000000000006  :  3\n",
      "bin:len 0.8800000000000006  :  1\n",
      "bin:len 0.8900000000000006  :  3\n",
      "bin:len 0.9000000000000006  :  16\n",
      "bin:len 0.9100000000000006  :  18\n",
      "bin:len 0.9200000000000006  :  28\n",
      "bin:len 0.9300000000000006  :  31\n",
      "bin:len 0.9400000000000006  :  30\n",
      "bin:len 0.9500000000000006  :  21\n",
      "bin:len 0.9600000000000006  :  27\n",
      "bin:len 0.9700000000000006  :  16\n",
      "bin:len 0.9800000000000006  :  11\n",
      "bin:len 0.9900000000000007  :  64\n",
      "trained data 1733\n",
      "validation data 1440\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "sample_bin_start = 0.0\n",
    "sample_bin_end = 1.0\n",
    "sample_bin_step = 0.01\n",
    "current_bin_data = []\n",
    "    \n",
    "while current_bin<sample_bin_end:\n",
    "    current_bin_data = [data for data in modified_data if (current_bin < abs(data[1])) and (abs(data[1])<=current_bin+step)]\n",
    "    extract_data_from_bin(current_bin_data)\n",
    "    print(\"bin:len\", current_bin, \" : \", len(current_bin_data) )\n",
    "    current_bin = current_bin+step\n",
    "        \n",
    "zero_bin = [data for data in modified_data if (data[1]==0.0)]\n",
    "extract_data_from_bin(zero_bin)\n",
    "\n",
    "training_data = np.array(training_data)\n",
    "validation_data = np.array(validation_data)\n",
    "        \n",
    "#draw_data_hist(abs(training_data[:,1]), 'train angles');\n",
    "#draw_data_hist(abs(validation_data[:,1]), 'validation angles');\n",
    "\n",
    "print(\"trained data\", len(training_data))\n",
    "print(\"validation data\", len(validation_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation angles saved to pickle file\n"
     ]
    }
   ],
   "source": [
    "# prepare data to save\n",
    "\n",
    "pickle_data = []\n",
    "validation_pickle = []\n",
    "\n",
    "for row in training_data:  \n",
    "    pickle_data.append({ 'center': row[0], 'angle': row[1] })\n",
    "    \n",
    "for row in validation_data:  \n",
    "    validation_pickle.append({ 'center': row[0], 'angle': row[1] })\n",
    "    \n",
    "training_file = 'train.p'\n",
    "with open(\"data/\"+training_file, 'wb') as handle:\n",
    "    pickle.dump(np.array(pickle_data), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "validation_file = 'validation.p'\n",
    "with open(\"data/\"+validation_file, 'wb') as handle:\n",
    "    pickle.dump(np.array(validation_pickle), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Training and validation angles saved to pickle file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMAGE PRE-PROCESSING TECHNIQUES\n",
    "\"\"\"\n",
    "def img_pre_process(image):\n",
    "    roi = image[60:140, :, :] #Cut top and bottom of image\n",
    "    image = cv2.resize(roi, (64,64), interpolation=cv2.INTER_AREA) #reducing image size so that model runs faster\n",
    "    return image\n",
    "\n",
    "#Image brigtness method\n",
    "#Credit: https://github.com/mohankarthik/CarND-BehavioralCloning-P3/blob/master/model.py\n",
    "def img_change_brightness(img):\n",
    "    # Convert the image to HSV\n",
    "    temp = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Compute a random brightness value and apply to the image\n",
    "    brightness = 0.25 + np.random.uniform()\n",
    "    temp[:, :, 2] = temp[:, :, 2] * brightness\n",
    "\n",
    "    # Convert back to RGB and return\n",
    "    return cv2.cvtColor(temp, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "#translate image and compensate for the translation on the steering angle\n",
    "def translate_image(image, steering, horz_range=30, vert_range=5):\n",
    "    rows, cols, chs = image.shape\n",
    "    tx = np.random.randint(-horz_range, horz_range+1)\n",
    "    ty = np.random.randint(-vert_range, vert_range+1)\n",
    "    steering = steering + tx * 0.004 # multiply by steering angle units per pixel\n",
    "    tr_M = np.float32([[1,0,tx], [0,1,ty]])\n",
    "    image = cv2.warpAffine(image, tr_M, (cols,rows), borderMode=1)\n",
    "    return image, steering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER_PATH = 'data'\n",
    "\n",
    "def read_image(image_path):\n",
    "    full_image_path = os.path.join(FOLDER_PATH, image_path.strip())\n",
    "    image = mpimg.imread(full_image_path)\n",
    "    return img_pre_process(image)\n",
    "\n",
    "# flipping, to avoid bias to left\\right turns\n",
    "# brightness, augmentaion to generalize to t2\n",
    "# translate, to simulate the car being at the edges of the road and hill-slopes\n",
    "# translate is done both on normal and flipped images\n",
    "def generate_steering_angle(data, batch_size=128):\n",
    "    X = []\n",
    "    Y = []\n",
    "    while True:\n",
    "        data = shuffle(data)    \n",
    "        for line in data:\n",
    "            image = read_image(line['center'])\n",
    "            angle = line['angle']\n",
    "            image_brightened = img_change_brightness(image)\n",
    "            X.append(image_brightened)\n",
    "            Y.append(angle)\n",
    "            \n",
    "            flipped_image = cv2.flip(image, 1)\n",
    "            flipped_image_brightened = img_change_brightness(flipped_image)\n",
    "            X.append(flipped_image_brightened)\n",
    "            Y.append(-angle)\n",
    "            \n",
    "            translated_image, translated_angle = translate_image(image_brightened, angle)\n",
    "            X.append(translated_image)\n",
    "            Y.append(translated_angle)\n",
    "\n",
    "            translated_flipped_image, translated_flipped_angle = translate_image(flipped_image_brightened, angle)\n",
    "            X.append(translated_flipped_image)\n",
    "            Y.append(translated_flipped_angle)\n",
    "\n",
    "            if len(X)>=batch_size:\n",
    "                X, Y = shuffle(X, Y)\n",
    "                yield np.array(X), np.array(Y) # (image, steering angle)\n",
    "                X=[]\n",
    "                Y=[]\n",
    "            \n",
    "\n",
    "def generate_validation(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    while True:\n",
    "        data = shuffle(data)\n",
    "        for line in data:\n",
    "            angle = line['angle']\n",
    "            image = read_image(line['center'])\n",
    "\n",
    "            X.append(image)\n",
    "            Y.append(angle)\n",
    "            yield np.array(X), np.array(Y) # (image, steering angle)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=[64, 64, 3])\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # and a regression layer to predict steering angle\n",
    "    x = Dense(1000, activation='relu', name='fc1', W_regularizer=l2(0.0001))(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(250, activation='relu', name='fc2', W_regularizer=l2(0.0001))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1)(x)\n",
    "\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    # train only the top layers (which were randomly initialized)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 1733\n",
      "validation size 1440\n",
      "Epoch 1/5\n",
      "6912/6932 [============================>.] - ETA: 0s - loss: 82.1391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khaleel.pasha/anaconda/envs/selfDrivingCarCourseEnvironment/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6944/6932 [==============================] - 301s - loss: 81.7619 - val_loss: 0.3844\n",
      "Epoch 2/5\n",
      "6944/6932 [==============================] - 309s - loss: 0.4340 - val_loss: 0.3619\n",
      "Epoch 3/5\n",
      "6944/6932 [==============================] - 316s - loss: 0.4142 - val_loss: 0.3119\n",
      "Epoch 4/5\n",
      "6944/6932 [==============================] - 304s - loss: 0.4022 - val_loss: 0.2905\n",
      "Epoch 5/5\n",
      "6944/6932 [==============================] - 1933s - loss: 0.3824 - val_loss: 0.2594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121e3b358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "training_pickle = 'data/train.p'\n",
    "with open(training_pickle, 'rb') as handle:\n",
    "    driving_info = pickle.load(handle)\n",
    "\n",
    "validation_pickle = 'data/validation.p'\n",
    "with open(validation_pickle, 'rb') as handle:\n",
    "    validation_info = pickle.load(handle)\n",
    "    \n",
    "print(\"train size\", len(driving_info))\n",
    "print(\"validation size\", len(validation_info))\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(\n",
    "    generate_steering_angle(driving_info, batch_size=32),\n",
    "    samples_per_epoch=len(driving_info)*4, \n",
    "    nb_epoch=5,\n",
    "    validation_data=generate_validation(validation_info),\n",
    "    nb_val_samples=len(validation_info)/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "model_json = 'model.json'\n",
    "model_weights = 'model.h5'\n",
    "\n",
    "json_string = model.to_json()\n",
    "try:\n",
    "    os.remove(model_json)\n",
    "    os.remove(model_weights)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with open(model_json, 'w') as jfile:\n",
    "    json.dump(json_string, jfile)\n",
    "model.save(model_weights)\n",
    "\n",
    "print(\"model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
